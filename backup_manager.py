#!/usr/bin/env python3
"""
è³‡æ–™åº«å‚™ä»½ç®¡ç†ç³»çµ±
æ”¯æ´æœ¬åœ°å‚™ä»½ã€é›²ç«¯åŒæ­¥å’Œè‡ªå‹•æ¸…ç†
"""

import os
import sys
import shutil
import sqlite3
import json
import zipfile
from datetime import datetime, timedelta
from pathlib import Path
import subprocess
import logging

# é…ç½®æ—¥èªŒ
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('backup.log'),
        logging.StreamHandler()
    ]
)

class BackupManager:
    def __init__(self, app=None):
        self.app = app
        self.backup_dir = Path('backups')
        self.backup_dir.mkdir(exist_ok=True)
        
        # å‚™ä»½é…ç½®
        self.config = {
            'max_backups': 10,  # ä¿ç•™çš„æœ€å¤§å‚™ä»½æ•¸é‡
            'backup_interval_hours': 24,  # å‚™ä»½é–“éš”ï¼ˆå°æ™‚ï¼‰
            'compress_backups': True,  # æ˜¯å¦å£“ç¸®å‚™ä»½
            'cloud_sync': False,  # æ˜¯å¦å•Ÿç”¨é›²ç«¯åŒæ­¥
            'cloud_drive_path': None,  # é›²ç«¯ç¡¬ç¢Ÿè·¯å¾‘
        }
        
        # è¼‰å…¥é…ç½®
        self.load_config()
    
    def load_config(self):
        """è¼‰å…¥å‚™ä»½é…ç½®"""
        config_file = Path('backup_config.json')
        if config_file.exists():
            try:
                with open(config_file, 'r', encoding='utf-8') as f:
                    saved_config = json.load(f)
                    self.config.update(saved_config)
                logging.info("âœ… å‚™ä»½é…ç½®å·²è¼‰å…¥")
            except Exception as e:
                logging.error(f"âŒ è¼‰å…¥é…ç½®å¤±æ•—: {e}")
    
    def save_config(self):
        """ä¿å­˜å‚™ä»½é…ç½®"""
        try:
            with open('backup_config.json', 'w', encoding='utf-8') as f:
                json.dump(self.config, f, indent=2, ensure_ascii=False)
            logging.info("âœ… å‚™ä»½é…ç½®å·²ä¿å­˜")
        except Exception as e:
            logging.error(f"âŒ ä¿å­˜é…ç½®å¤±æ•—: {e}")
    
    def create_backup(self, backup_name=None):
        """å‰µå»ºè³‡æ–™åº«å‚™ä»½"""
        try:
            if not backup_name:
                timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                backup_name = f"backup_{timestamp}"
            
            backup_path = self.backup_dir / backup_name
            backup_path.mkdir(exist_ok=True)
            
            # å‚™ä»½è³‡æ–™åº«
            db_source = Path('instance/sales_system_v4.db')
            if not db_source.exists():
                logging.error("âŒ è³‡æ–™åº«æª”æ¡ˆä¸å­˜åœ¨")
                return False
            
            db_backup = backup_path / 'sales_system_v4.db'
            shutil.copy2(db_source, db_backup)
            
            # å‚™ä»½é…ç½®æª”æ¡ˆ
            config_files = [
                'backup_config.json',
                'requirements.txt',
                '.flaskenv'
            ]
            
            for config_file in config_files:
                if Path(config_file).exists():
                    shutil.copy2(config_file, backup_path)
            
            # å‰µå»ºå‚™ä»½è³‡è¨Šæª”æ¡ˆ
            backup_info = {
                'backup_time': datetime.now().isoformat(),
                'backup_name': backup_name,
                'database_size': db_source.stat().st_size,
                'files_backed_up': [f.name for f in backup_path.iterdir()],
                'version': '1.0.0'
            }
            
            with open(backup_path / 'backup_info.json', 'w', encoding='utf-8') as f:
                json.dump(backup_info, f, indent=2, ensure_ascii=False)
            
            # å£“ç¸®å‚™ä»½ï¼ˆå¦‚æœå•Ÿç”¨ï¼‰
            if self.config['compress_backups']:
                self.compress_backup(backup_path)
                # åˆªé™¤æœªå£“ç¸®çš„ç›®éŒ„
                shutil.rmtree(backup_path)
                backup_path = Path(f"{backup_path}.zip")
            
            logging.info(f"âœ… å‚™ä»½å‰µå»ºæˆåŠŸ: {backup_path}")
            
            # æ¸…ç†èˆŠå‚™ä»½
            self.cleanup_old_backups()
            
            # é›²ç«¯åŒæ­¥ï¼ˆå¦‚æœå•Ÿç”¨ï¼‰
            if self.config['cloud_sync']:
                self.sync_to_cloud(backup_path)
            
            return True
            
        except Exception as e:
            logging.error(f"âŒ å‰µå»ºå‚™ä»½å¤±æ•—: {e}")
            return False
    
    def compress_backup(self, backup_path):
        """å£“ç¸®å‚™ä»½ç›®éŒ„"""
        try:
            zip_path = f"{backup_path}.zip"
            with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
                for file_path in backup_path.rglob('*'):
                    if file_path.is_file():
                        arcname = file_path.relative_to(backup_path)
                        zipf.write(file_path, arcname)
            
            logging.info(f"âœ… å‚™ä»½å·²å£“ç¸®: {zip_path}")
            
        except Exception as e:
            logging.error(f"âŒ å£“ç¸®å‚™ä»½å¤±æ•—: {e}")
    
    def cleanup_old_backups(self):
        """æ¸…ç†èˆŠå‚™ä»½"""
        try:
            # ç²å–æ‰€æœ‰å‚™ä»½æª”æ¡ˆ
            backup_files = []
            for file_path in self.backup_dir.iterdir():
                if file_path.is_file() and (file_path.suffix == '.zip' or file_path.is_dir()):
                    backup_files.append(file_path)
            
            # æŒ‰ä¿®æ”¹æ™‚é–“æ’åº
            backup_files.sort(key=lambda x: x.stat().st_mtime, reverse=True)
            
            # åˆªé™¤è¶…å‡ºæ•¸é‡é™åˆ¶çš„å‚™ä»½
            if len(backup_files) > self.config['max_backups']:
                for old_backup in backup_files[self.config['max_backups']:]:
                    if old_backup.is_dir():
                        shutil.rmtree(old_backup)
                    else:
                        old_backup.unlink()
                    logging.info(f"ğŸ—‘ï¸  å·²åˆªé™¤èˆŠå‚™ä»½: {old_backup}")
            
        except Exception as e:
            logging.error(f"âŒ æ¸…ç†èˆŠå‚™ä»½å¤±æ•—: {e}")
    
    def sync_to_cloud(self, backup_path):
        """åŒæ­¥åˆ°é›²ç«¯ç¡¬ç¢Ÿ"""
        if not self.config['cloud_drive_path']:
            logging.warning("âš ï¸  é›²ç«¯ç¡¬ç¢Ÿè·¯å¾‘æœªè¨­å®š")
            return
        
        try:
            cloud_path = Path(self.config['cloud_drive_path'])
            if not cloud_path.exists():
                logging.error(f"âŒ é›²ç«¯ç¡¬ç¢Ÿè·¯å¾‘ä¸å­˜åœ¨: {cloud_path}")
                return
            
            # è¤‡è£½å‚™ä»½åˆ°é›²ç«¯
            cloud_backup = cloud_path / backup_path.name
            if backup_path.is_dir():
                shutil.copytree(backup_path, cloud_backup, dirs_exist_ok=True)
            else:
                shutil.copy2(backup_path, cloud_backup)
            
            logging.info(f"â˜ï¸  å‚™ä»½å·²åŒæ­¥åˆ°é›²ç«¯: {cloud_backup}")
            
        except Exception as e:
            logging.error(f"âŒ é›²ç«¯åŒæ­¥å¤±æ•—: {e}")
    
    def restore_backup(self, backup_name):
        """å¾å‚™ä»½æ¢å¾©è³‡æ–™åº«"""
        try:
            backup_path = self.backup_dir / backup_name
            
            # æª¢æŸ¥å‚™ä»½æ˜¯å¦å­˜åœ¨
            if not backup_path.exists():
                if Path(f"{backup_path}.zip").exists():
                    backup_path = Path(f"{backup_path}.zip")
                else:
                    logging.error(f"âŒ å‚™ä»½ä¸å­˜åœ¨: {backup_name}")
                    return False
            
            # å¦‚æœæ˜¯å£“ç¸®æª”æ¡ˆï¼Œå…ˆè§£å£“
            if backup_path.suffix == '.zip':
                extract_path = backup_path.with_suffix('')
                with zipfile.ZipFile(backup_path, 'r') as zipf:
                    zipf.extractall(extract_path)
                backup_path = extract_path
            
            # æ¢å¾©è³‡æ–™åº«
            db_backup = backup_path / 'sales_system_v4.db'
            if not db_backup.exists():
                logging.error("âŒ å‚™ä»½ä¸­æ‰¾ä¸åˆ°è³‡æ–™åº«æª”æ¡ˆ")
                return False
            
            # å‚™ä»½ç•¶å‰è³‡æ–™åº«
            current_db = Path('instance/sales_system_v4.db')
            if current_db.exists():
                timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                safety_backup = Path(f"instance/sales_system_v4_safety_{timestamp}.db")
                shutil.copy2(current_db, safety_backup)
                logging.info(f"âœ… ç•¶å‰è³‡æ–™åº«å·²å‚™ä»½: {safety_backup}")
            
            # æ¢å¾©å‚™ä»½
            shutil.copy2(db_backup, current_db)
            logging.info(f"âœ… è³‡æ–™åº«å·²å¾å‚™ä»½æ¢å¾©: {backup_name}")
            
            return True
            
        except Exception as e:
            logging.error(f"âŒ æ¢å¾©å‚™ä»½å¤±æ•—: {e}")
            return False
    
    def list_backups(self):
        """åˆ—å‡ºæ‰€æœ‰å‚™ä»½"""
        try:
            backups = []
            for file_path in self.backup_dir.iterdir():
                if file_path.is_file() and (file_path.suffix == '.zip' or file_path.is_dir()):
                    stat = file_path.stat()
                    backup_info = {
                        'name': file_path.name,
                        'size': stat.st_size,
                        'modified': datetime.fromtimestamp(stat.st_mtime),
                        'type': 'zip' if file_path.suffix == '.zip' else 'folder'
                    }
                    backups.append(backup_info)
            
            # æŒ‰ä¿®æ”¹æ™‚é–“æ’åº
            backups.sort(key=lambda x: x['modified'], reverse=True)
            
            return backups
            
        except Exception as e:
            logging.error(f"âŒ åˆ—å‡ºå‚™ä»½å¤±æ•—: {e}")
            return []
    
    def get_backup_status(self):
        """ç²å–å‚™ä»½ç‹€æ…‹"""
        try:
            backups = self.list_backups()
            latest_backup = backups[0] if backups else None
            
            status = {
                'total_backups': len(backups),
                'latest_backup': latest_backup,
                'backup_dir': str(self.backup_dir.absolute()),
                'config': self.config,
                'next_backup_time': None
            }
            
            if latest_backup:
                next_backup = latest_backup['modified'] + timedelta(hours=self.config['backup_interval_hours'])
                status['next_backup_time'] = next_backup
            
            return status
            
        except Exception as e:
            logging.error(f"âŒ ç²å–å‚™ä»½ç‹€æ…‹å¤±æ•—: {e}")
            return {}

def create_backup_command():
    """å‰µå»ºå‚™ä»½çš„å‘½ä»¤è¡Œä»‹é¢"""
    import argparse
    
    parser = argparse.ArgumentParser(description='è³‡æ–™åº«å‚™ä»½ç®¡ç†å·¥å…·')
    parser.add_argument('action', choices=['create', 'restore', 'list', 'status', 'config'],
                       help='åŸ·è¡Œçš„æ“ä½œ')
    parser.add_argument('--name', help='å‚™ä»½åç¨±')
    parser.add_argument('--max-backups', type=int, help='æœ€å¤§å‚™ä»½æ•¸é‡')
    parser.add_argument('--interval', type=int, help='å‚™ä»½é–“éš”ï¼ˆå°æ™‚ï¼‰')
    parser.add_argument('--cloud-sync', action='store_true', help='å•Ÿç”¨é›²ç«¯åŒæ­¥')
    parser.add_argument('--cloud-path', help='é›²ç«¯ç¡¬ç¢Ÿè·¯å¾‘')
    
    args = parser.parse_args()
    
    manager = BackupManager()
    
    if args.action == 'create':
        success = manager.create_backup(args.name)
        if success:
            print("âœ… å‚™ä»½å‰µå»ºæˆåŠŸ")
        else:
            print("âŒ å‚™ä»½å‰µå»ºå¤±æ•—")
    
    elif args.action == 'restore':
        if not args.name:
            print("âŒ è«‹æŒ‡å®šè¦æ¢å¾©çš„å‚™ä»½åç¨±")
            return
        
        success = manager.restore_backup(args.name)
        if success:
            print("âœ… å‚™ä»½æ¢å¾©æˆåŠŸ")
        else:
            print("âŒ å‚™ä»½æ¢å¾©å¤±æ•—")
    
    elif args.action == 'list':
        backups = manager.list_backups()
        if backups:
            print(f"ğŸ“‹ æ‰¾åˆ° {len(backups)} å€‹å‚™ä»½:")
            for backup in backups:
                print(f"  {backup['name']} - {backup['modified']} ({backup['size']} bytes)")
        else:
            print("ğŸ“‹ æ²’æœ‰æ‰¾åˆ°å‚™ä»½")
    
    elif args.action == 'status':
        status = manager.get_backup_status()
        print("ğŸ“Š å‚™ä»½ç‹€æ…‹:")
        print(f"  ç¸½å‚™ä»½æ•¸é‡: {status['total_backups']}")
        print(f"  å‚™ä»½ç›®éŒ„: {status['backup_dir']}")
        if status['latest_backup']:
            print(f"  æœ€æ–°å‚™ä»½: {status['latest_backup']['name']}")
            print(f"  å‚™ä»½æ™‚é–“: {status['latest_backup']['modified']}")
        if status['next_backup_time']:
            print(f"  ä¸‹æ¬¡å‚™ä»½: {status['next_backup_time']}")
    
    elif args.action == 'config':
        if args.max_backups:
            manager.config['max_backups'] = args.max_backups
        if args.interval:
            manager.config['backup_interval_hours'] = args.interval
        if args.cloud_sync is not None:
            manager.config['cloud_sync'] = args.cloud_sync
        if args.cloud_path:
            manager.config['cloud_drive_path'] = args.cloud_path
        
        manager.save_config()
        print("âœ… é…ç½®å·²æ›´æ–°")

if __name__ == "__main__":
    create_backup_command()
